**Date：03/25/2025**。

本文整理自Galileo AI博客: [Benchmarks and Use Cases for Multi‑Agent AI](https://galileo.ai/blog/benchmarks-multi-agent-ai)，旨在帮助读者快速了解当前主要的多智能体（multi‑agent）系统基准，并了解其适用场景和特点。

## 多智能体AI基准的重要性

多智能体AI系统通过多个智能体相互协作或竞争来解决复杂问题，其特性包括集体决策、任务分工和涌现行为。与单一智能体评测不同，多智能体基准需要考察智能体之间的互动、沟通和协调能力——尤其是共享资源、意图传达及合作完成复杂任务的能力。一个好的多智能体基准应包含：

* 多样化场景和环境，能检验合作与竞争；
* 针对协调协议、通信方式的评测；
* 既考察任务完成率，又衡量协作质量。

## 主要基准比较一览

下表列出了文章中分析的七个代表性基准。表格仅列出关键领域和主要优势；详细描述请参见后文。

| 基准 | 关注领域 | 优势 | 适用场景 | 局限 |
| :--- | :--- | :--- | :--- | :--- |
| [**MultiAgentBench**](https://arxiv.org/html/2503.01935v1) | LLM‑驱动多智能体评测 | 模块化、支持多种协调拓扑（星形/链/树/图），设有里程碑关键指标 | 研究‑产品过渡、需要可复现的企业部署 | 对简单应用可能过于复杂 |
| [**BattleAgentBench**](https://arxiv.org/abs/2408.15971) | 合作与竞争能力 | 难度分级的七个子阶段，可精细评估合作和竞争 | 市场模拟、自动化交易、谈判框架 | 侧重语言模型，缺乏对其他类型智能体的评测 |
| [**SOTOPIA‑π**](https://arxiv.org/abs/2403.08715) | 社会智能 | 沉浸式社交场景，评估同理心、社会规范、伦理决策 | 客户服务、医疗、教育助手 | 可能无法充分衡量技术能力 |
| [**MARL‑EVAL**](https://arxiv.org/html/2502.04773v1) | 多智能体强化学习（MARL） | 统计严格，提供置信区间和显著性检验；分析协同模式和专业化发展 | 机器人、自动驾驶、工业自动化 | 主要针对强化学习，不涵盖其他类型 |
| [**AgentVerse**](https://arxiv.org/abs/2308.10848) | 多样交互范式 | 环境丰富（合作任务、竞争游戏、创意任务等），支持不同体系结构和通信协议 | 探索多种架构的研究团队 | 学习曲线较陡 |
| [**SmartPlay**](https://arxiv.org/abs/2310.01557) | 战略推理和规划 | 利用经典和现代策略游戏，注重策略深度、对手建模和适应性 | 金融规划、商业智能、战略系统 | 游戏环境与某些领域不易直接对应 |
| [**Who&When**](https://arxiv.org/abs/2505.00212) | 多智能体系统中的故障归因 | 提供带有真人标注的大量故障日志数据集，用于开发和评估自动化故障归因方法。 | 调试和提升多智能体系统的可靠性。 | 专注于故障分析，而非评估成功任务的性能。 |

## 各基准详细解析

### 1. MultiAgentBench

MultiAgentBench是一个面向语言模型驱动智能体的全面评测框架，通过多种互动场景评估智能体的合作和竞争能力。其特点包括：

* **多种协调拓扑**：评测不同的协调结构（星形、链式、树型及图结构）以及群体讨论、认知规划等策略，从而探索适合不同任务的协同方式。
* **模块化设计**：支持替换或扩展智能体、环境及LLM集成；实现分层或协作执行模式，并提供共享内存用于通信。
* **企业级实现**：提供Docker环境，代码质量高、文档齐全，便于在不同系统部署，适合研究成果向生产应用转换。

这一基准主要适合需要评估复杂协作策略或希望在企业环境中应用多智能体系统的团队。对于简单任务，复杂的配置可能是负担。

### 2. BattleAgentBench

[BattleAgentBench](https://arxiv.org/html/2503.01935v1)专为语言模型设计，强调在合作与竞争场景中的表现。它设置了七个难度递增的子阶段，从单智能体到多智能体协作与竞争。该基准突出：

* **分级难度**：通过逐步增加复杂度，细致评估模型在不同层次上的表现差异。
* **性能差距洞察**：揭示闭源API模型与开源小模型在简单任务上的差异，并指出即使顶级模型在复杂任务中仍有提升空间。
* **真实决策环境**：模拟需要在自利与团队目标之间权衡的决策情景，为市场模拟、自动化交易及多方谈判系统的开发提供参考。

由于主要衡量语言模型，非语言型智能体在此基准中的表现可能难以体现。

### 3. SOTOPIA‑π

SOTOPIA‑π针对多智能体系统中的社会智能，构建沉浸式社交仿真环境。智能体需要理解社会规范、表现出同理心并在文化语境下作出适当反应。重要特点包括：

* **多层次社交情景**：涵盖双人互动及多人场景，考察视角转换、冲突解决和道德决策等社会认知能力。
* **社会适应性评估**：通过考察社会适当性和伦理推理，发现传统技术性基准难以暴露的社会智能缺陷。

该基准适合开发人机交互系统的机构，如医疗、客户服务和教育技术公司，帮助评估智能体在复杂社交情境下的可靠性。

### 4. MARL‑EVAL

MARL‑EVAL是用于评测多智能体强化学习系统的标准化框架。它侧重于适应性、协调效率及群体中专门化的形成。主要特点有：

* **统计严谨**：提供性能指标的置信区间和显著性检验，使不同系统之间的比较更可靠。
* **多样测试**：包含标准和对抗性环境，检验系统在不同条件下的鲁棒性。
* **协同模式分析**：提供工具追踪训练过程中协调模式和专门化发展，帮助理解智能体如何达成合作。

该框架适用于开发动态环境中多智能体系统的团队，如机器人群体、自动驾驶和工业自动化。由于其聚焦强化学习，可能不适用于非RL架构。

### 5. AgentVerse

AgentVerse提供一个支持多种交互范式的评测平台，强调环境的多样性与架构灵活性。其优势在于：

* **环境多样**：涵盖合作问题解决、竞技游戏、创意任务和模拟环境，便于比较不同架构在各领域的表现。
* **通信与协调评测**：评估智能体传达意图、协调行动及适应变化的能力，并提供详细日志和可视化工具，帮助理解复杂互动。
* **架构兼容性**：支持多种智能体设计和通信协议，适合探索架构创新的研究团队。

这个基准被多家顶尖实验室用于系统性比较不同设计范式。由于功能丰富，新手可能需要一定学习成本。

### 6. SmartPlay

SmartPlay通过策略游戏评测智能体的战略推理和规划能力。它不仅关注胜率，还衡量决策深度和适应性。特征包括：

* **策略深度评估**：考察智能体如何制定反制策略、适应对手模式，并在短期战术与长期目标之间权衡。
* **决策过程分析**：追踪决策质量、规划视野和策略适应，帮助研究者理解智能体的推理过程。

适用于需要评估战略制定能力的应用，如金融规划、商业情报和军事战略系统。不过，由于基于游戏环境，结果可能不易直接迁移至其他领域。

### 7. Who&When

Who&When 是一个专注于新兴研究领域——多智能体系统自动化故障归因——的基准。它不评估智能体的性能，而是旨在识别哪个智能体以及哪个具体步骤导致了任务失败。主要特点包括：

*   **以故障为中心的数据集**：该基准提供了“Who&When”数据集，其中包含来自127个不同多智能体系统的大量故障日志。
*   **人工标注的真实标签**：每个故障日志都经过人工标注，以确定责任智能体和关键错误步骤，为评估提供了可靠的基准真相。
*   **归因方法评估**：该基准主要用于开发和测试自动化故障归因方法。原始论文提出了三种基线方法，并在该数据集上评估了它们的性能。

对于致力于提高复杂多智能体系统可靠性和可调试性的开发人员和研究人员来说，这个基准非常宝贵。它为构建和验证能够自动诊断故障的工具提供了必要的资源，这是迈向更稳健、更可信的智能体系统的关键一步。

## 如何选择合适的基准

选择基准时，需要考虑系统的目标和使用场景。若重点是语言模型在复杂协作中的表现，可优先考虑MultiAgentBench或BattleAgentBench；若需要评估社会互动能力，则SOTOPIA‑π是理想选择；对于强化学习系统，MARL‑EVAL提供了严格的统计评估；如果关注架构比较和广泛交互范式，AgentVerse是不错的工具；而需要验证战略规划的应用，可以使用SmartPlay；对于需要调试和理解多智能体系统故障模式的场景，Who&When数据集为故障归因提供了宝贵的资源。

此外，文章指出，单一基准往往难以捕捉实际应用中的所有性能指标。Galileo为此提供了实时监控、成本效率分析、语言模型作为评判者的定性评估和自动化测试管道等工具。这些高级评测手段有助于在部署阶段更全面地了解多智能体系统的行为和成本效益。


本文整理自Galileo AI博客: [Benchmarks and Use Cases for Multi‑Agent AI](https://galileo.ai/blog/benchmarks-multi-agent-ai)，旨在帮助读者快速了解当前主要的多智能体（multi‑agent）系统基准，并了解其适用场景和特点。

## 多智能体AI基准的重要性

多智能体AI系统通过多个智能体相互协作或竞争来解决复杂问题，其特性包括集体决策、任务分工和涌现行为。与单一智能体评测不同，多智能体基准需要考察智能体之间的互动、沟通和协调能力——尤其是共享资源、意图传达及合作完成复杂任务的能力。一个好的多智能体基准应包含：

* 多样化场景和环境，能检验合作与竞争；
* 针对协调协议、通信方式的评测；
* 既考察任务完成率，又衡量协作质量。

## 主要基准比较一览

下表列出了文章中分析的七个代表性基准。表格仅列出关键领域和主要优势；详细描述请参见后文。

| 基准                                                         | 关注领域           | 优势                                  | 适用场景               | 局限                   |
| ---------------------------------------------------------- | -------------- | ----------------------------------- | ------------------ | -------------------- |
| [**MultiAgentBench**](https://arxiv.org/html/2503.01935v1) | LLM‑驱动多智能体评测   | 模块化、支持多种协调拓扑（星形/链/树/图），设有里程碑关键指标    | 研究‑产品过渡、需要可复现的企业部署 | 对简单应用可能过于复杂          |
| [**BattleAgentBench**](https://arxiv.org/abs/2408.15971)   | 合作与竞争能力        | 难度分级的七个子阶段，可精细评估合作和竞争               | 市场模拟、自动化交易、谈判框架    | 侧重语言模型，缺乏对其他类型智能体的评测 |
| [**SOTOPIA‑π**](https://arxiv.org/abs/2403.08715)          | 社会智能           | 沉浸式社交场景，评估同理心、社会规范、伦理决策             | 客户服务、医疗、教育助手       | 可能无法充分衡量技术能力         |
| [**MARL‑EVAL**](https://arxiv.org/html/2502.04773v1)       | 多智能体强化学习（MARL） | 统计严格，提供置信区间和显著性检验；分析协同模式和专业化发展      | 机器人、自动驾驶、工业自动化     | 主要针对强化学习，不涵盖其他类型     |
| [**AgentVerse**](https://arxiv.org/abs/2308.10848)         | 多样交互范式         | 环境丰富（合作任务、竞争游戏、创意任务等），支持不同体系结构和通信协议 | 探索多种架构的研究团队        | 学习曲线较陡               |
| [**SmartPlay**](https://arxiv.org/abs/2310.01557)          | 战略推理和规划        | 利用经典和现代策略游戏，注重策略深度、对手建模和适应性         | 金融规划、商业智能、战略系统     | 游戏环境与某些领域不易直接对应      |
| **行业专用基准**                                                 | 特定业务领域         | 融合领域知识和合规要求，关注商业结果                  | 供应链优化、医疗协同、金融合规等   | 跨行业可迁移性有限            |

## 各基准详细解析

### 1. MultiAgentBench

MultiAgentBench是一个面向语言模型驱动智能体的全面评测框架，通过多种互动场景评估智能体的合作和竞争能力。其特点包括：

* **多种协调拓扑**：评测不同的协调结构（星形、链式、树型及图结构）以及群体讨论、认知规划等策略，从而探索适合不同任务的协同方式。
* **模块化设计**：支持替换或扩展智能体、环境及LLM集成；实现分层或协作执行模式，并提供共享内存用于通信。
* **企业级实现**：提供Docker环境，代码质量高、文档齐全，便于在不同系统部署，适合研究成果向生产应用转换。

这一基准主要适合需要评估复杂协作策略或希望在企业环境中应用多智能体系统的团队。对于简单任务，复杂的配置可能是负担。

### 2. BattleAgentBench

[BattleAgentBench](https://arxiv.org/html/2503.01935v1)专为语言模型设计，强调在合作与竞争场景中的表现。它设置了七个难度递增的子阶段，从单智能体到多智能体协作与竞争。该基准突出：

* **分级难度**：通过逐步增加复杂度，细致评估模型在不同层次上的表现差异。
* **性能差距洞察**：揭示闭源API模型与开源小模型在简单任务上的差异，并指出即使顶级模型在复杂任务中仍有提升空间。
* **真实决策环境**：模拟需要在自利与团队目标之间权衡的决策情景，为市场模拟、自动化交易及多方谈判系统的开发提供参考。

由于主要衡量语言模型，非语言型智能体在此基准中的表现可能难以体现。

### 3. SOTOPIA‑π

SOTOPIA‑π针对多智能体系统中的社会智能，构建沉浸式社交仿真环境。智能体需要理解社会规范、表现出同理心并在文化语境下作出适当反应。重要特点包括：

* **多层次社交情景**：涵盖双人互动及多人场景，考察视角转换、冲突解决和道德决策等社会认知能力。
* **社会适应性评估**：通过考察社会适当性和伦理推理，发现传统技术性基准难以暴露的社会智能缺陷。

该基准适合开发人机交互系统的机构，如医疗、客户服务和教育技术公司，帮助评估智能体在复杂社交情境下的可靠性。

### 4. MARL‑EVAL

MARL‑EVAL是用于评测多智能体强化学习系统的标准化框架。它侧重于适应性、协调效率及群体中专门化的形成。主要特点有：

* **统计严谨**：提供性能指标的置信区间和显著性检验，使不同系统之间的比较更可靠。
* **多样测试**：包含标准和对抗性环境，检验系统在不同条件下的鲁棒性。
* **协同模式分析**：提供工具追踪训练过程中协调模式和专门化发展，帮助理解智能体如何达成合作。

该框架适用于开发动态环境中多智能体系统的团队，如机器人群体、自动驾驶和工业自动化。由于其聚焦强化学习，可能不适用于非RL架构。

### 5. AgentVerse

AgentVerse提供一个支持多种交互范式的评测平台，强调环境的多样性与架构灵活性。其优势在于：

* **环境多样**：涵盖合作问题解决、竞技游戏、创意任务和模拟环境，便于比较不同架构在各领域的表现。
* **通信与协调评测**：评估智能体传达意图、协调行动及适应变化的能力，并提供详细日志和可视化工具，帮助理解复杂互动。
* **架构兼容性**：支持多种智能体设计和通信协议，适合探索架构创新的研究团队。

这个基准被多家顶尖实验室用于系统性比较不同设计范式。由于功能丰富，新手可能需要一定学习成本。

### 6. SmartPlay

SmartPlay通过策略游戏评测智能体的战略推理和规划能力。它不仅关注胜率，还衡量决策深度和适应性。特征包括：

* **策略深度评估**：考察智能体如何制定反制策略、适应对手模式，并在短期战术与长期目标之间权衡。
* **决策过程分析**：追踪决策质量、规划视野和策略适应，帮助研究者理解智能体的推理过程。

适用于需要评估战略制定能力的应用，如金融规划、商业情报和军事战略系统。不过，由于基于游戏环境，结果可能不易直接迁移至其他领域。

### 7. 行业专用基准

针对特定行业的基准结合了领域知识与实际业务需求，强调符合商业目标和合规要求。特点如下：

* **领域针对性**：通过与行业专家合作，设计符合真实业务流程和监管要求的评测指标。
* **实际场景模拟**：基于现实运营场景构建测试环境，比一般技术性基准更能预测系统在实际部署中的表现。
* **示例领域**：供应链优化评估物流协调，医疗协同评估患者路径与资源调度，金融服务评估智能体处理复杂监管任务。

此类基准适用于拥有明确业务ROI需求的垂直领域部署，但缺乏跨领域适用性。

## 如何选择合适的基准

选择基准时，需要考虑系统的目标和使用场景。若重点是语言模型在复杂协作中的表现，可优先考虑MultiAgentBench或BattleAgentBench；若需要评估社会互动能力，则SOTOPIA‑π是理想选择；对于强化学习系统，MARL‑EVAL提供了严格的统计评估；如果关注架构比较和广泛交互范式，AgentVerse是不错的工具；而需要验证战略规划的应用，可以使用SmartPlay；垂直行业则应选择行业专用基准。

此外，文章指出，单一基准往往难以捕捉实际应用中的所有性能指标。Galileo为此提供了实时监控、成本效率分析、语言模型作为评判者的定性评估和自动化测试管道等工具。这些高级评测手段有助于在部署阶段更全面地了解多智能体系统的行为和成本效益。